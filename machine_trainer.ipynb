{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506, \n",
      "accuracy of the machine is : 0.6809245483528161\n",
      "accuracy of the machine is : 0.6487778958554729\n",
      "accuracy of the machine is : 0.7173219978746015\n",
      "accuracy of the machine is : 0.6880977683315622\n",
      "accuracy of the machine is : 0.7420297555791711\n",
      "accuracy of the machine is : 0.7130712008501594\n",
      "0:05:56.582110\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import nltk as n\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "startTime = datetime.now()\n",
    "\n",
    "cwd = str(Path.home())\n",
    "masterloc=cwd+\"/moviereviews/masterfile.txt\"\n",
    "stopwords = n.corpus.stopwords.words('english')\n",
    "total_set=[]\n",
    "test_set=[]\n",
    "dev_set=[]\n",
    "train_set=[]\n",
    "\n",
    "    \n",
    "\n",
    "def machine_features(characters,pos_tagged_s,review,sn):\n",
    "    #print(\"in machine feature\")\n",
    "    reviewSentence_list=n.tokenize.sent_tokenize(review)\n",
    "    reviewlist=n.tokenize.word_tokenize(review)\n",
    "    tot_features_dic={}\n",
    "    tot_features_dic.update(char_feature(characters,reviewlist))\n",
    "    tot_features_dic.update(verb_feature(pos_tagged_s,reviewlist))\n",
    "    tot_features_dic.update(sentenceVerb_features(characters,pos_tagged_s,reviewSentence_list))\n",
    "    total_set.append((tot_features_dic,sn))\n",
    "        \n",
    "def sentenceVerb_features(characters,pos_tagged_s,reviewSentence_list):\n",
    "    VB_list=[\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"]\n",
    "    verblist_s=[x for x,y in pos_tagged_s if y in VB_list]\n",
    "    total_sentences = len(reviewSentence_list)\n",
    "    tot_occ_char_verb = 0\n",
    "    for i in reviewSentence_list:\n",
    "        if(len(i)!=0):\n",
    "            v_bool=False\n",
    "            c_bool=False\n",
    "            words = n.tokenize.word_tokenize(i)\n",
    "            pos_tagged_r = n.pos_tag(words)\n",
    "            pos_tagged_r=[(w,l) for w,l in pos_tagged_r if w not in stopwords]\n",
    "            for x in characters:\n",
    "                x=x.lower()\n",
    "                if x in words:\n",
    "                    c_bool=True\n",
    "                    break        \n",
    "            for x,y in pos_tagged_r:\n",
    "                if y in VB_list and x in verblist_s:\n",
    "                    v_bool=True\n",
    "                    break\n",
    "            if c_bool and v_bool:\n",
    "                tot_occ_char_verb = tot_occ_char_verb + 1\n",
    "    per_occ_char_verb = tot_occ_char_verb/total_sentences\n",
    "    return({\"percentage_of_occurrence_character_verb\":per_occ_char_verb})\n",
    "    \n",
    "def char_feature(characters,reviewlist):\n",
    "    tot_occ_char=0\n",
    "    per_tot_occ_char=0\n",
    "    if len(reviewlist)!=0:\n",
    "        for i in characters:\n",
    "            i=i.lower()\n",
    "            tot_occ_char+=reviewlist.count(i)\n",
    "        per_tot_occ_char=tot_occ_char/len(reviewlist)\n",
    "    return ({\"percentage_of_occurence_character\":per_tot_occ_char})\n",
    "\n",
    "def verb_feature(pos_tagged_s,reviewlist):\n",
    "    #print(\"in verb feature\")\n",
    "    pos_tagged_r=n.pos_tag(reviewlist)\n",
    "    pos_tagged_r=[(w,l) for w,l in pos_tagged_r if w not in stopwords]\n",
    "    tot_occ_verb=0\n",
    "    per_tot_occ_verb=0\n",
    "    VB_list=[\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"]\n",
    "    verblist_s=[x for x,y in pos_tagged_s if y in VB_list]\n",
    "    verblist_r=[x for x,y in pos_tagged_r if y in VB_list]\n",
    "    if len(reviewlist)!=0:\n",
    "        for i in verblist_r:\n",
    "            if i in verblist_s:\n",
    "                tot_occ_verb+=synopsislist.count(i)\n",
    "        per_tot_occ_verb=tot_occ_verb/len(reviewlist)\n",
    "    return ({\"percentage_of_occurence_verb\":per_tot_occ_verb})\n",
    "\n",
    "    \n",
    "def trainmachine1(t_set):\n",
    "    return n.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "def trainmachine2(t_set):\n",
    "    return n.DecisionTreeClassifier.train(train_set)\n",
    "\n",
    "def trainmachine3(t_set):\n",
    "    return SklearnClassifier(SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), sparse=False).train(t_set)\n",
    "\n",
    "def testmachine(machine,t_set):\n",
    "    print(\"accuracy of the machine is : {}\".format(n.classify.accuracy(machine,t_set)))\n",
    "\n",
    "def storetotalset(t_set):\n",
    "    total_set_location=cwd+\"/moviereviews/total_set.data\"\n",
    "    f=open(total_set_location,\"wb\")\n",
    "    pickle.dump(total_set,f)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "f1 = open(masterloc)\n",
    "count=0\n",
    "stopwords\n",
    "for i in f1.readlines():\n",
    "    count+=1\n",
    "    print(count,end=\",\")\n",
    "    moviehash=i.rstrip(\"\\n\")\n",
    "    movie_loc=cwd+\"/moviereviews/\"+moviehash\n",
    "\n",
    "\n",
    "    movie_n_loc=movie_loc+\"/\"+moviehash+\".txt\"\n",
    "    #movie_n=open(movie_n_loc).readline()\n",
    "\n",
    "\n",
    "    movie_s_loc=movie_loc+\"/\"+moviehash+\"_s.txt\"\n",
    "    movie_s=open(movie_s_loc).read()\n",
    "\n",
    "    \n",
    "    synopsislist=n.word_tokenize(movie_s)                 # pos tagging synopsis early to avoid it doing again and again\n",
    "    pos_tagged_s=n.pos_tag(synopsislist)\n",
    "    pos_tagged_s=[(w,l) for w,l in pos_tagged_s if w not in stopwords]\n",
    "\n",
    "    movie_c_loc=movie_loc+\"/\"+moviehash+\"_c.txt\"\n",
    "    movie_c=[j.rstrip(\"\\n\") for j in open(movie_c_loc).readlines()]\n",
    "\n",
    "    for i in range(25):\n",
    "        movie_r_loc=movie_loc+\"/\"+moviehash+\"_\"+str(i+1)+\".txt\"\n",
    "        if os.path.isfile(movie_r_loc)==True:\n",
    "            f=open(movie_r_loc)\n",
    "            reviewnumber,sn=f.readline().rstrip(\"\\n\").split(\",\")\n",
    "            review=f.readline()\n",
    "            review=review.lower()\n",
    "            if review!=\"\":\n",
    "                \n",
    "                machine_features(movie_c,pos_tagged_s,review,sn)\n",
    "            f.close()\n",
    "f1.close()\n",
    "\n",
    "storetotalset(total_set)\n",
    "\n",
    "\n",
    "tt=len(total_set)\n",
    "#train_set=total_set[:int(0.4*tt)]\n",
    "#dev_set=total_set[int(0.4*tt)+1:int(0.7*tt)]\n",
    "#test_set=total_set[int(0.7*tt)+1:]\n",
    "    \n",
    "print(\" \")\n",
    "test_set=total_set[:int(0.3*tt)]\n",
    "train_set=total_set[int(0.3*tt)+1:int(0.7*tt)]\n",
    "dev_set=total_set[int(0.7*tt)+1:]\n",
    "        \n",
    "    \n",
    "machine1=trainmachine1(train_set)\n",
    "machine2=trainmachine2(train_set)\n",
    "testmachine(machine1,test_set)\n",
    "testmachine(machine1,dev_set)\n",
    "testmachine(machine2,test_set)\n",
    "testmachine(machine2,dev_set)\n",
    "\n",
    "\n",
    "\n",
    "#machine.show_most_informative_features()\n",
    "print(datetime.now() - startTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506, \n",
      "detected1 1498\n",
      "notdetected1 1178\n",
      "detected2 1039\n",
      "notdetected2 338\n",
      "detected3 0\n",
      "notdetected3 0\n",
      "total 3255\n"
     ]
    }
   ],
   "source": [
    "#for checking total accuracy\n",
    "\n",
    "t_set=[]\n",
    "for x,y in total_set:\n",
    "    flag=False\n",
    "    for a,b in x.items():\n",
    "        if b==0.0:\n",
    "            flag=True\n",
    "    if flag==False:\n",
    "        t_set.append((x,y))\n",
    "\n",
    "count=0\n",
    "total=0\n",
    "detected1=0\n",
    "notdetected1=0\n",
    "detected2=0\n",
    "notdetected2=0\n",
    "detected3=0\n",
    "notdetected3=0\n",
    "counter=0\n",
    "f1 = open(masterloc)\n",
    "for i in f1.readlines():\n",
    "    counter+=1\n",
    "    print(counter,end=\",\")\n",
    "    moviehash=i.rstrip(\"\\n\")\n",
    "    movie_loc=cwd+\"/moviereviews/\"+moviehash\n",
    "    \n",
    "    \n",
    "    movie_n_loc=movie_loc+\"/\"+moviehash+\".txt\"\n",
    "    movie_n=open(movie_n_loc).readline()\n",
    "    \n",
    "    \n",
    "    movie_s_loc=movie_loc+\"/\"+moviehash+\"_s.txt\"\n",
    "    movie_s=open(movie_s_loc).read()\n",
    "    synopsislist=n.word_tokenize(movie_s)                 # pos tagging synopsis early to avoid it doing again and again\n",
    "    pos_tagged_s=n.pos_tag(synopsislist)\n",
    "    pos_tagged_s=[(w,l) for w,l in pos_tagged_s if w not in stopwords]\n",
    "    \n",
    "    movie_c_loc=movie_loc+\"/\"+moviehash+\"_c.txt\"\n",
    "    movie_c=[j.rstrip(\"\\n\") for j in open(movie_c_loc).readlines()]\n",
    "    \n",
    "    for i in range(25):\n",
    "        \n",
    "        movie_r_loc=movie_loc+\"/\"+moviehash+\"_\"+str(i+1)+\".txt\"\n",
    "        if os.path.isfile(movie_r_loc)==True:\n",
    "            f=open(movie_r_loc)\n",
    "            reviewnumber,sn=f.readline().rstrip(\"\\n\").split(\",\")\n",
    "            review=f.readline().lower()\n",
    "            f.close()\n",
    "            if review!=\"\":\n",
    "                reviewSentence_list=n.tokenize.sent_tokenize(review)\n",
    "                reviewlist=n.tokenize.word_tokenize(review)\n",
    "                tot_features_dic={}\n",
    "                tot_features_dic.update(char_feature(movie_c,reviewlist))\n",
    "                tot_features_dic.update(verb_feature(pos_tagged_s,reviewlist))\n",
    "                tot_features_dic.update(sentenceVerb_features(movie_c,pos_tagged_s,reviewSentence_list))\n",
    "                t3=machine3.classify(tot_features_dic) \n",
    "                t2=machine2.classify(tot_features_dic) \n",
    "                t1=machine1.classify(tot_features_dic) \n",
    "                count+=1\n",
    "                if t3==\"S\" and sn==\"S\":\n",
    "                    detected1+=1\n",
    "                if sn==\"S\":\n",
    "                    total+=1\n",
    "                if t3==\"S\" and sn!=\"S\":\n",
    "                    notdetected1+=1\n",
    "                if t2==\"S\" and sn==\"S\":\n",
    "                    detected2+=1\n",
    "                if t2==\"S\" and sn!=\"S\":\n",
    "                    notdetected2+=1\n",
    "                if t1==\"S\" and sn==\"S\":\n",
    "                    detected1+=1\n",
    "                if t1==\"S\" and sn!=\"S\":\n",
    "                    notdetected1+=1\n",
    "                \n",
    "f1.close()\n",
    "print(\" \")\n",
    "print(\"detected1\",detected1)\n",
    "print(\"notdetected1\",notdetected1)\n",
    "print(\"detected2\",detected2)\n",
    "print(\"notdetected2\",notdetected2)\n",
    "print(\"detected3\",detected3)\n",
    "print(\"notdetected3\",notdetected3)\n",
    "print(\"total\",total)\n",
    "\n",
    "#print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishvapatel/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the machine is : 0.6950053134962806\n",
      "accuracy of the machine is : 0.6866861546638321\n",
      "accuracy of the machine is : 0.5454303931987248\n",
      "accuracy of the machine is : 0.5530162104703694\n",
      "accuracy of the machine is : 0.7457492029755579\n",
      "accuracy of the machine is : 0.733723093276641\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishvapatel/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the machine is : 0.7037725823591924\n",
      "accuracy of the machine is : 0.6995217853347503\n",
      "accuracy of the machine is : 0.7035069075451648\n",
      "accuracy of the machine is : 0.7088204038257173\n",
      "accuracy of the machine is : 0.7420297555791711\n",
      "accuracy of the machine is : 0.7457492029755579\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "total=random.sample(total_set,len(total_set))\n",
    "train_set=total[:int(0.4*tt)]\n",
    "dev_set=total[int(0.4*tt)+1:int(0.7*tt)]\n",
    "test_set=total[int(0.7*tt)+1:]\n",
    "\n",
    "machine1=trainmachine1(train_set)\n",
    "machine2=trainmachine2(train_set)\n",
    "machine3=trainmachine3(train_set)\n",
    "testmachine(machine1,test_set)\n",
    "testmachine(machine1,dev_set)\n",
    "testmachine(machine2,test_set)\n",
    "testmachine(machine2,dev_set)\n",
    "testmachine(machine3,test_set)\n",
    "testmachine(machine3,dev_set)\n",
    "\n",
    "machine1.show_most_informative_features()\n",
    "machine2.show_most_informative_features()\n",
    "machine3.show_most_informative_features()\n",
    "\n",
    "test_set=total[:int(0.3*tt)]\n",
    "train_set=total[int(0.3*tt)+1:int(0.7*tt)]\n",
    "dev_set=total[int(0.7*tt)+1:]\n",
    "print(\"\")\n",
    "\n",
    "machine1=trainmachine1(train_set)\n",
    "machine2=trainmachine2(train_set)\n",
    "machine3=trainmachine3(train_set)\n",
    "testmachine(machine1,test_set)\n",
    "testmachine(machine1,dev_set)\n",
    "testmachine(machine2,test_set)\n",
    "testmachine(machine2,dev_set)\n",
    "testmachine(machine3,test_set)\n",
    "testmachine(machine3,dev_set)\n",
    "\n",
    "machine1.show_most_informative_features()\n",
    "machine2.show_most_informative_features()\n",
    "machine3.show_most_informative_features()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the machine is : 0.7420297555791711\n",
      "accuracy of the machine is : 0.7130712008501594\n",
      "<SklearnClassifier(SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))>\n"
     ]
    }
   ],
   "source": [
    "testmachine(machine3,test_set)\n",
    "testmachine(machine3,dev_set)\n",
    "print(machine3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vishvapatel/moviereviews/total_set.data\n"
     ]
    }
   ],
   "source": [
    "print(total_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "total_set_location=cwd+\"/moviereviews/total_set.data\"\n",
    "f=open(total_set_location,\"wb\")\n",
    "pickle.dump(total_set,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 'hello', ('hi', {'hello': 2})]\n"
     ]
    }
   ],
   "source": [
    "f=open(total_set_location,\"rb\")\n",
    "tl=pickle.load(f)\n",
    "f.close()\n",
    "print(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vishvapatel/moviereviews/total_set.data\n"
     ]
    }
   ],
   "source": [
    "print(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7420297555791711\n",
      "Enter urlhttps://www.imdb.com/title/tt1772341/?ref_=nv_sr_srsg_0\n",
      "\n",
      "\n",
      "Wreck-It Ralph\n",
      "Enter reviewDisney animation has been trying to capture the magic of Pixar movies for a while now. They normally produce quality pictures, but more often than not Pixar films are on a higher level than the computer animated Disney films. Even though Pixar is owned by Disney there is still the attempt to create non-Pixar computer animation that will be able to stand out for the entertainment monster that Disney is.  Wreck-It Ralph is the story of Ralph (John C. Reilly), the villain of an arcade game called \"Fix-It Felix Jr.\" which it is clear draws influence from the original \"Donkey Kong\" game. Villains are never appreciated for being evil. The main point of most games is simply to take down the villain. How can one feel appreciated when everyone else only wants to beat them back? Ralph leaves his own game in an attempt to become a hero in the arcade. After earning a medal in a futuristic war game, \"Hero's Duty\", Ralph jumps to a candy themed racing game, \"Sugar Rush\". While in the game Ralph meets Vanellope (Sarah Silverman), a young girl whose only dream is to become a racer, but every other racer in the kingdom considers her a mistake. Even King Candy (Alan Tudyk) refuses to let a glitch race in the game. Fix-It Felix Jr. (Jack MacBrayer) and Calhoun (Jane Lynch) travel into the colorful racing world in search of Ralph and a rogue bug from Calhoun's game, \"Hero's Duty\". The story that develops involves an unlikely friendship, a sinister plot and a villain realizing what it truly means to be a hero.  A well thought out and well scripted story provide the back bone to this movie, video game references and cameos adds meat to the body and with great casting choices to wrap the characters up with fitting voices the movie becomes its own stand-alone entity. There are a few moments in which the script resorts to crude jokes and toilet humor, but the dialogue works with the characters to provide a humorous and entertaining movie. Continuity is one thing that is very easy to keep within a movie as long as the script is edited and thought through. There are a few minor inconsistencies in this movie and a few scenes left unexplained, but these minor inconsistencies do not make the movie confusing or difficult to follow.  Typically I prefer Pixar films over the Disney computer animation, however this year between Brave and Wreck-It Ralph I prefer the Disney computer animation.\n",
      "N\n",
      "conty\n",
      "Enter reviewA large part of the movie's success was is due to its tribute to the classical video games, and how accurately it captured the essence of each type of video game while also making them original. Disney studio revisits the 8-bit graphics used in 1820s video games, such as Donkey Kong. The characters from retro games continue to move in the jerky 8-bit movement even when the animation switches back to the modern high definition graphics. The 80s avatars also speak in the particular language from that time period. Specifically, Felix frequently exclaims antiquated expressions like \"That's just the honey glow in my cheeks!\" Such minutia evokes a nostalgic feeling.  But the best parts of the movie were the romance between Felix and Calhoun, especially since the two had completely polar personalities, and the credits. Felix falls for Calhoun at first sight and continues to woo her with his classic pick-up lines. Calhoun attempts to brush off his courtship with her crude, sarcastic comebacks, which will definitely remind Glee-fans of Sue Sylvester. During the credits, Owl City's When Can I See You Again plays as the four main characters, Ralph, Vanellope, Felix, and Calhoun game hop through most games in the arcade and interact with game characters who had little to no parts in the actual movie. Their images changes in each game as they adapt to each game. \"Wreck It Ralph\" also had an awesome soundtrack that suited each scene so well that you'd think each song was made with the sole purpose to be played in this movie. The soundtrack of \"Wreck It Ralph,\" mostly composed by Henry Jackman, also features artists such as Rihanna and AKB48, a popular Japanese girl band.  One of the few complaints is the lack of racial diversity within the human characters. Most of the video game characters were Caucasian as well, but even more so in the real world. There are only a few human characters in the film, but the majority of them are white. There was also no need for the movie to be in 3D, especially since there were not many notable pop-ups utilizing the 3 dimensional effect. The 3D glasses only made the screen darker and harder to see than it already was\n",
      "N\n",
      "conty\n",
      "Enter reviewA large part of the movie's success was is due to its tribute to the classical video games, and how accurately it captured the essence of each type of video game while also making them original. Disney studio revisits the 8-bit graphics used in 1820s video games, such as Donkey Kong. The characters from retro games continue to move in the jerky 8-bit movement even when the animation switches back to the modern high definition graphics. The 80s avatars also speak in the particular language from that time period. Specifically, Felix frequently exclaims antiquated expressions like That's just the honey glow in my cheeks! Such minutia evokes a nostalgic feelingBut the best parts of the movie were the romance between Felix and Calhoun, especially since the two had completely polar personalities, and the credits. Felix falls for Calhoun at first sight and continues to woo her with his classic pick-up lines. Calhoun attempts to brush off his courtship with her crude, sarcastic comebacks, which will definitely remind Glee-fans of Sue Sylvester. During the credits, Owl City's When Can I See You Again plays as the four main characters, Ralph, Vanellope, Felix, and Calhoun game hop through most games in the arcade and interact with game characters who had little to no parts in the actual movie. Their images changes in each game as they adapt to each game.  also had an awesome soundtrack that suited each scene so well that you'd think each song was made with the sole purpose to be played in this movie. The soundtrack of  mostly composed by Henry Jackman, also features artists such as Rihanna and AKB48, a popular Japanese girl bandOne of the few complaints is the lack of racial diversity within the human characters. Most of the video game characters were Caucasian as well, but even more so in the real world. There are only a few human characters in the film, but the majority of them are white. There was also no need for the movie to be in 3D, especially since there were not many notable pop-ups utilizing the 3 dimensional effect. The 3D glasses only made the screen darker and harder to see than it already wa\n",
      "N\n",
      "contn\n"
     ]
    }
   ],
   "source": [
    "print(n.classify.accuracy(machine3,test_set))\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def Scrape(url_raw):\n",
    "    urllist = url_raw.split(\"/\")\n",
    "    urllist = urllist[0:-1]\n",
    "    url = \"\"\n",
    "    for i in urllist:\n",
    "        url = url + i + \"/\"\n",
    "    url_s = url+\"synopsis\"        #url for extracting synopsis and MovieTitle\n",
    "    url_c = url+\"fullcredits\"     #url for extracting characters\n",
    "    try:\n",
    "        page = urlopen(url_c)\n",
    "    except:\n",
    "        print(\"Error opening the URL\")\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "\n",
    "    content = soup.find_all('td', {\"class\": \"character\"})\n",
    "\n",
    "    characterlist = []\n",
    "    for i in content:\n",
    "        if(i.find('a')!=None):\n",
    "            characterlist.append(i.find('a').text)\n",
    "   #print(characterlist)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        page = urlopen(url_s)\n",
    "    except:\n",
    "        print(\"Error opening the URL\")\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    content = soup.find('ul', {\"id\": \"plot-synopsis-content\"})\n",
    "    title = soup.find('div',{\"class\":\"parent\"})\n",
    "    MovieTitle = title.find('a').text\n",
    "    #rint(MovieTitle)\n",
    "    synopsis = ''\n",
    "    for i in content.findAll('li'):\n",
    "        synopsis = synopsis + i.text\n",
    "\n",
    "    #rint(synopsis)\n",
    "    return (MovieTitle,characterlist,synopsis)\n",
    "\n",
    "url = input(\"Enter url\")\n",
    "movie_t,movie_c,movie_s = Scrape(url)\n",
    "synopsislist=n.word_tokenize(movie_s)                 # pos tagging synopsis early to avoid it doing again and again\n",
    "pos_tagged_s=n.pos_tag(synopsislist)\n",
    "print(movie_t)   \n",
    "while True:    \n",
    "    review= input(\"Enter review\")\n",
    "    reviewSentence_list=n.tokenize.sent_tokenize(review)\n",
    "    reviewlist=n.tokenize.word_tokenize(review)\n",
    "    \n",
    "    pos_tagged_s=[(w,l) for w,l in pos_tagged_s if w not in stopwords]\n",
    "    tot_feature_dic={}\n",
    "    tot_feature_dic.update(char_feature(movie_c,reviewlist))\n",
    "    tot_feature_dic.update(verb_feature(pos_tagged_s,reviewlist))\n",
    "    tot_feature_dic.update(sentenceVerb_features(movie_c,pos_tagged_s,reviewSentence_list))\n",
    "    print(machine2.classify(tot_feature_dic))\n",
    "    if input(\"cont\")!=\"y\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'how', 'are', 'you', 'i', 'am', 'fine', 'hello', 'how', 'are', 'you', 'do', 'i', 'am', 'go', 'for', 'a', 'swim']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "str=\"hello how are you i am fine \\\"hello\\\" how are you doing i am going for a swim \"\n",
    "list=n.word_tokenize(str)\n",
    "list=[word for word in list if word.isalnum()]\n",
    "list=[porter.stem(word) for word in list]\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
